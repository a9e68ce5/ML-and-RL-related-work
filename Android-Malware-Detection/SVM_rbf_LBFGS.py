import numpy as np
import pandas as pd
import os
import matplotlib.pyplot as plt
from cvxopt import matrix, solvers
from scipy.optimize import minimize

# -------------------------------
# 1. 資料讀取與前處理
# -------------------------------
def load_data(train_file, test_file):
    train_df = pd.read_csv(train_file)
    test_df = pd.read_csv(test_file)
    # 假設標籤欄位名稱為 "label"，其他以 x 開頭的欄位為特徵
    X_train = train_df.filter(regex="^x").values
    y_train = train_df['label'].values
    X_test = test_df.filter(regex="^x").values
    y_test = test_df['label'].values
    return X_train, y_train, X_test, y_test

def standardize_data(X, mean=None, std=None):
    if mean is None or std is None:
        mean = np.mean(X, axis=0)
        std = np.std(X, axis=0)
    std[std == 0] = 1
    X_std = (X - mean) / std
    return X_std, mean, std

# -------------------------------
# 2. PCA：根據累積解釋變異（例如 80%）決定保留主成分數目
# -------------------------------
def perform_pca(X, variance_threshold=0.8):
    mean = np.mean(X, axis=0)
    X_centered = X - mean
    cov_matrix = np.cov(X_centered, rowvar=False)
    eigenvalues, eigenvectors = np.linalg.eigh(cov_matrix)
    sorted_idx = np.argsort(eigenvalues)[::-1]
    eigenvalues = eigenvalues[sorted_idx]
    eigenvectors = eigenvectors[:, sorted_idx]
    explained_variances = eigenvalues / np.sum(eigenvalues)
    cumulative_variance = np.cumsum(explained_variances)
    k = np.searchsorted(cumulative_variance, variance_threshold) + 1
    eigenvectors_reduced = eigenvectors[:, :k]
    X_reduced = np.dot(X_centered, eigenvectors_reduced)
    return X_reduced, eigenvectors_reduced, mean, k, cumulative_variance

# -------------------------------
# 3. RBF kernel 與 SVM
# -------------------------------
def rbf_kernel(X1, X2, gamma):
    X1_sq = np.sum(X1**2, axis=1).reshape(-1, 1)
    X2_sq = np.sum(X2**2, axis=1).reshape(1, -1)
    dist_sq = X1_sq + X2_sq - 2 * np.dot(X1, X2.T)
    dist_sq = np.maximum(dist_sq, 0)
    return np.exp(-gamma * dist_sq)

def svm_train(X, y, C, kernel_func, gamma, tol=1e-4):
    n_samples = X.shape[0]
    K = kernel_func(X, X, gamma)
    P = matrix(np.outer(y, y) * K)
    q = matrix(-np.ones(n_samples))
    G_std = np.diag(-np.ones(n_samples))
    h_std = np.zeros(n_samples)
    G_slack = np.diag(np.ones(n_samples))
    h_slack = np.ones(n_samples) * C
    G = matrix(np.vstack((G_std, G_slack)))
    h = matrix(np.hstack((h_std, h_slack)))
    A = matrix(y.reshape(1, -1))
    b = matrix(np.zeros(1))
    solvers.options['show_progress'] = False
    solution = solvers.qp(P, q, G, h, A, b)
    alphas = np.ravel(solution['x'])
    sv = alphas > tol
    ind = np.arange(len(alphas))[sv]
    alphas_sv = alphas[sv]
    sv_X = X[sv]
    sv_y = y[sv]
    # 計算 b
    b_val = 0
    for n in range(len(alphas_sv)):
        b_val += sv_y[n] - np.sum(alphas_sv * sv_y * K[ind[n], sv])
    b_val /= len(alphas_sv)
    model = {
        'alphas': alphas_sv,
        'sv_X': sv_X,
        'sv_y': sv_y,
        'b': b_val,
        'gamma': gamma,
        'kernel_func': kernel_func
    }
    return model

def svm_decision_function(model, X):
    alphas = model['alphas']
    sv_X = model['sv_X']
    sv_y = model['sv_y']
    b_val = model['b']
    gamma = model['gamma']
    kernel_func = model['kernel_func']
    K = kernel_func(X, sv_X, gamma)
    decision_values = np.dot(K, alphas * sv_y) + b_val
    return decision_values

def svm_predict(model, X, use_calibration=False, threshold=0.5):
    decision_values = svm_decision_function(model, X)
    if use_calibration and 'calibration_method' in model:
        method = model['calibration_method']
        if method == 'temperature_scaling':
            T = model['calibration']
            prob = 1.0 / (1.0 + np.exp(-decision_values / T))
        else:
            # 預設: 不校準
            prob = 1.0 / (1.0 + np.exp(-decision_values))
        predictions = np.where(prob >= threshold, 1, -1)
        return predictions, prob
    else:
        predictions = np.sign(decision_values)
        return predictions, decision_values

def accuracy_score(y_true, y_pred):
    return np.mean(y_true == y_pred)

# -------------------------------
# 4. Temperature Scaling 校準 (LBFGS)
# -------------------------------
def calibrate_model_temperature_scaling(model, X_calib, y_calib):
    """
    使用 LBFGS 來最小化 cross-entropy，尋找最佳溫度 T。
    """
    decision_values = svm_decision_function(model, X_calib)
    y_calib_binary = np.where(y_calib == -1, 0, 1).astype(float)
    
    # 目標函式：負對數似然 (cross-entropy)
    # 我們用 logT 來確保 T>0
    def objective(logT):
        T = np.exp(logT)  # 使 T>0
        x = decision_values / T
        p = 1.0 / (1.0 + np.exp(-x))
        # cross-entropy
        # -sum( y*log(p) + (1-y)*log(1-p) )
        eps = 1e-12
        ce = -np.sum(y_calib_binary * np.log(p + eps) + (1 - y_calib_binary) * np.log(1 - p + eps))
        return ce
    
    # 以 0 為初始值 => T=exp(0)=1
    res = minimize(objective, x0=0.0, method='L-BFGS-B')
    best_logT = res.x[0]
    best_T = np.exp(best_logT)
    
    model['calibration_method'] = 'temperature_scaling'
    model['calibration'] = best_T
    return model

# -------------------------------
# 5. 評估指標 (F1-score) 與閾值搜尋
# -------------------------------
def compute_f1_score(y_true, y_pred):
    tp = np.sum((y_true == 1) & (y_pred == 1))
    fp = np.sum((y_true == -1) & (y_pred == 1))
    fn = np.sum((y_true == 1) & (y_pred == -1))
    if tp == 0:
        return 0.0
    precision = tp / (tp + fp) if (tp + fp) != 0 else 0.0
    recall = tp / (tp + fn) if (tp + fn) != 0 else 0.0
    if precision + recall == 0:
        return 0.0
    return 2 * precision * recall / (precision + recall)

def find_optimal_threshold_f1(probs, true_labels):
    thresholds = np.linspace(0, 1, 1001)
    best_thresh = 0.5
    best_f1 = 0.0
    for thresh in thresholds:
        preds = np.where(probs >= thresh, 1, -1)
        f1 = compute_f1_score(true_labels, preds)
        if f1 > best_f1:
            best_f1 = f1
            best_thresh = thresh
    return best_thresh, best_f1

# -------------------------------
# 6. 資料分布分析
# -------------------------------
def analyze_distribution(X_train, X_test, X_eval):
    stats = {
        'train_mean': np.mean(X_train, axis=0),
        'test_mean': np.mean(X_test, axis=0),
        'eval_mean': np.mean(X_eval, axis=0),
        'train_std': np.std(X_train, axis=0),
        'test_std': np.std(X_test, axis=0),
        'eval_std': np.std(X_eval, axis=0)
    }
    return stats

# -------------------------------
# 7. 繪製校準曲線
# -------------------------------
def plot_calibration_curve(probs, true_labels, n_bins=10):
    bin_edges = np.linspace(0, 1, n_bins + 1)
    bin_true = np.zeros(n_bins)
    bin_pred = np.zeros(n_bins)
    bin_counts = np.zeros(n_bins)
    
    for p, t in zip(probs, true_labels):
        bin_idx = np.digitize(p, bin_edges, right=True) - 1
        bin_idx = np.clip(bin_idx, 0, n_bins - 1)
        bin_true[bin_idx] += t
        bin_pred[bin_idx] += p
        bin_counts[bin_idx] += 1
        
    nonzero = bin_counts > 0
    avg_true = np.zeros(n_bins)
    avg_pred = np.zeros(n_bins)
    avg_true[nonzero] = bin_true[nonzero] / bin_counts[nonzero]
    avg_pred[nonzero] = bin_pred[nonzero] / bin_counts[nonzero]
    
    plt.figure(figsize=(8, 6))
    plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Perfect Calibration')
    plt.plot(avg_pred, avg_true, marker='o', linewidth=2, label='Calibration Curve')
    plt.xlabel('Mean Predicted Probability')
    plt.ylabel('Fraction of Positives')
    plt.title('Calibration Curve')
    plt.legend()
    plt.show()

# -------------------------------
# 8. Hold-out 驗證 (網格搜尋 C, gamma) - 以 F1-score 為指標
# -------------------------------
def holdout_validation(X, y, c_values, gamma_values, validation_ratio=0.2, variance_threshold=0.9, tol=1e-4):
    n_samples = X.shape[0]
    indices = np.arange(n_samples)
    np.random.shuffle(indices)
    split = int(n_samples * (1 - validation_ratio))
    train_idx = indices[:split]
    val_idx = indices[split:]
    
    X_train_hold = X[train_idx]
    y_train_hold = y[train_idx]
    X_val_hold = X[val_idx]
    y_val_hold = y[val_idx]
    
    # 標準化 (以 hold-out 訓練集為基準)
    X_train_hold_std, hold_mean, hold_std = standardize_data(X_train_hold)
    X_val_hold_std, _, _ = standardize_data(X_val_hold, mean=hold_mean, std=hold_std)
    
    # PCA
    X_train_hold_pca, hold_pca_components, hold_pca_mean, k, _ = perform_pca(X_train_hold_std, variance_threshold=variance_threshold)
    X_val_hold_centered = X_val_hold_std - hold_pca_mean
    X_val_hold_pca = np.dot(X_val_hold_centered, hold_pca_components)
    
    results = {}
    for C in c_values:
        for gamma in gamma_values:
            model = svm_train(X_train_hold_pca, y_train_hold, C, rbf_kernel, gamma, tol)
            y_val_pred, _ = svm_predict(model, X_val_hold_pca)
            f1 = compute_f1_score(y_val_hold, y_val_pred)
            results[(C, gamma)] = f1
    best_combo = max(results, key=lambda cg: results[cg])
    return best_combo, results

# -------------------------------
# 9. 主流程
# -------------------------------
def main():
    # 設定要不要校準：'temperature_scaling' 或 'none'
    calibration_method = 'temperature_scaling'
    
    train_file = 'data/train.csv'
    test_file = 'data/test.csv'
    
    print("讀取訓練與測試資料...")
    X_train, y_train, X_test, y_test = load_data(train_file, test_file)
    
    # 將標籤轉換為 -1 / 1
    y_train = np.where(y_train == 0, -1, 1).astype(np.float64)
    y_test = np.where(y_test == 0, -1, 1).astype(np.float64)
    
    print("對訓練資料進行標準化...")
    X_train_std, train_mean, train_std = standardize_data(X_train)
    X_test_std, _, _ = standardize_data(X_test, mean=train_mean, std=train_std)
    
    print("對訓練資料執行 PCA ...")
    X_train_pca, pca_components, pca_mean, k, cumulative_variance = perform_pca(X_train_std, variance_threshold=0.95)
    print(f"PCA 完成，保留 {k} 個主成分")
    
    X_test_centered = X_test_std - pca_mean
    X_test_pca = np.dot(X_test_centered, pca_components)
    
    print("\n進行資料分布分析 (PCA 空間)：")
    stats = analyze_distribution(X_train_pca, X_test_pca, X_test_pca)
    print("訓練資料平均值：", stats['train_mean'])
    print("測試資料平均值：", stats['test_mean'])
    
    # (C, gamma) 網格搜尋 (Hold-out 驗證, F1-score)
    c_values = [0.1, 1, 10, 100]
    gamma_values = [0.01, 0.05, 0.1, 0.5, 1, 5, 10]
    print("\n開始 (C, gamma) 網格搜尋 (Hold-out 驗證, F1-score)...")
    best_combo, holdout_results = holdout_validation(X_train, y_train, c_values, gamma_values,
                                                     validation_ratio=0.2, variance_threshold=0.8, tol=1e-4)
    best_c, best_gamma = best_combo
    print("各組合 F1-score:")
    for combo, f1_val in holdout_results.items():
        print(f"  C={combo[0]}, gamma={combo[1]} -> F1-score: {f1_val*100:.2f}%")
    print(f"\nHold-out 驗證選出的最佳 (C, gamma) = ({best_c}, {best_gamma})")
    
    print(f"\n使用最佳 (C={best_c}, gamma={best_gamma}) 重新訓練模型 ...")
    best_model = svm_train(X_train_pca, y_train, best_c, rbf_kernel, best_gamma)
    
    y_train_pred, _ = svm_predict(best_model, X_train_pca)
    train_acc = accuracy_score(y_train, y_train_pred)
    y_test_pred, _ = svm_predict(best_model, X_test_pca)
    test_acc = accuracy_score(y_test, y_test_pred)
    print(f"完整訓練集 Accuracy: {train_acc*100:.2f}%，測試集 Accuracy: {test_acc*100:.2f}%")
    
    # -------------------------------
    # Temperature Scaling 校準 (LBFGS) 或不校準
    # -------------------------------
    if calibration_method == 'temperature_scaling':
        print("使用 Temperature Scaling (LBFGS) 校準...")
        best_model = calibrate_model_temperature_scaling(best_model, X_test_pca, y_test)
        print("校準完成。")
    else:
        print("不使用校準...")
    
    # 在測試集上搜尋最佳閾值（以 F1-score 為依據）
    _, test_probs = svm_predict(best_model, X_test_pca, use_calibration=(calibration_method != 'none'))
    optimal_thresh, best_f1 = find_optimal_threshold_f1(test_probs, y_test)
    print(f"從測試集選出的最佳閾值為 {optimal_thresh:.3f} (F1-score: {best_f1*100:.2f}%)")
    
    # 繪製校準曲線
    y_test_binary = np.where(y_test == -1, 0, 1)
    plot_calibration_curve(test_probs, y_test_binary, n_bins=10)
    
    # -------------------------------
    # 讀取 evaluation 資料並進行預測
    # -------------------------------
    print("\n讀取 evaluation 資料 ...")
    eval_df = pd.read_csv("data/eval.anon.csv")
    eval_ids = pd.read_csv("data/eval.id", header=None, names=["id"])
    
    X_eval = eval_df.filter(regex="^x").values
    X_eval_std, _, _ = standardize_data(X_eval, mean=train_mean, std=train_std)
    X_eval_centered = X_eval_std - pca_mean
    X_eval_pca = np.dot(X_eval_centered, pca_components)
    
    eval_stats = analyze_distribution(X_train_pca, X_test_pca, X_eval_pca)
    print("Evaluation 資料平均值：", eval_stats['eval_mean'])
    
    eval_pred, eval_prob = svm_predict(best_model, X_eval_pca, use_calibration=(calibration_method != 'none'),
                                       threshold=optimal_thresh)
    eval_pred_converted = np.where(eval_pred == -1, 0, 1)
    
    output_df = pd.DataFrame({"example_id": eval_ids["id"], "label": eval_pred_converted})
    output_folder = "SVM"
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)
    output_path = os.path.join(output_folder, "svm_eval_predictions_LBFGS.csv")
    output_df.to_csv(output_path, index=False)
    print(f"Evaluation 預測結果已寫入：{output_path}")

if __name__ == "__main__":
    main()
