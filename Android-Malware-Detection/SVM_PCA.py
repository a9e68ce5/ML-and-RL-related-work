import os
import pandas as pd
import numpy as np

###############################
# PCA 降維 (僅使用 numpy)
###############################
def pca_transform(X, n_components, W=None, mean=None):
    """
    如果未提供 W 與 mean，則計算 PCA 基底，否則利用已有的基底將 X 投影到 n_components 維空間
    """
    # 若沒有提供均值，先計算均值後中心化
    if mean is None:
        mean = np.mean(X, axis=0)
    X_centered = X - mean
    # 若沒有提供基底，就計算 SVD 得到主成分
    if W is None:
        U, S, Vt = np.linalg.svd(X_centered, full_matrices=False)
        W = Vt[:n_components].T  # W 的每一列是主成分方向
    # 將 X 投影到 W 上
    X_reduced = np.dot(X_centered, W)
    return X_reduced, W, mean

###############################
# Kernel 函數定義
###############################
def linear_kernel(x, y, params=None):
    return np.dot(x, y)

def poly_kernel(x, y, params):
    gamma = params.get("gamma", 1.0)
    r = params.get("r", 1.0)
    degree = params.get("degree", 3)
    return (gamma * np.dot(x, y) + r) ** degree

def rbf_kernel(x, y, params):
    gamma = params.get("gamma", 0.05)
    diff = x - y
    return np.exp(-gamma * np.dot(diff, diff))

def sigmoid_kernel(x, y, params):
    gamma = params.get("gamma", 0.01)
    r = params.get("r", 0.0)
    return np.tanh(gamma * np.dot(x, y) + r)

def get_kernel_function(kernel_type, kernel_params):
    if kernel_type == "linear":
        return lambda x, y: linear_kernel(x, y)
    elif kernel_type == "poly":
        return lambda x, y: poly_kernel(x, y, kernel_params)
    elif kernel_type == "rbf":
        return lambda x, y: rbf_kernel(x, y, kernel_params)
    elif kernel_type == "sigmoid":
        return lambda x, y: sigmoid_kernel(x, y, kernel_params)
    else:
        raise ValueError("Unknown kernel type.")

###############################
# 資料標準化 (使用 numpy)
###############################
def standardize(X, mean=None, std=None):
    if mean is None:
        mean = np.mean(X, axis=0)
    if std is None:
        std = np.std(X, axis=0)
        std[std == 0] = 1.0
    return (X - mean) / std, mean, std

###############################
# SMO 演算法 (簡易版)
# 此版本會列出每個 epoch 的訓練情形
###############################
def smo_train(X, y, C=1.0, tol=1e-3, max_passes=5, kernel_func=None):
    n_samples = X.shape[0]
    alpha = np.zeros(n_samples)
    b = 0.0
    passes = 0
    epoch = 0

    # 預先計算完整的 kernel 矩陣
    K = np.zeros((n_samples, n_samples))
    for i in range(n_samples):
        for j in range(n_samples):
            K[i, j] = kernel_func(X[i], X[j])
    
    while passes < max_passes:
        epoch += 1
        num_changed_alphas = 0
        for i in range(n_samples):
            f_i = np.sum(alpha * y * K[:, i]) + b
            E_i = f_i - y[i]
            # 若該樣本違反 KKT 條件，就選擇作為第一候選
            if ((y[i] * E_i < -tol and alpha[i] < C) or (y[i] * E_i > tol and alpha[i] > 0)):
        
                # 第二個候選以隨機方式選取 (確保 j ≠ i)
                j = i
                while j == i:
                    j = np.random.randint(0, n_samples)
                f_j = np.sum(alpha * y * K[:, j]) + b
                E_j = f_j - y[j]

                alpha_i_old = alpha[i]
                alpha_j_old = alpha[j]

                # 計算上下界 L 與 H
                if y[i] != y[j]:
                    L = max(0, alpha[j] - alpha[i])
                    H = min(C, C + alpha[j] - alpha[i])
                else:
                    L = max(0, alpha[i] + alpha[j] - C)
                    H = min(C, alpha[i] + alpha[j])
                if L == H:
                    continue

                eta = 2 * K[i, j] - K[i, i] - K[j, j]
                if eta >= 0:
                    continue

                # 更新 alpha[j]
                alpha[j] = alpha[j] - (y[j]*(E_i - E_j)) / eta
                if alpha[j] > H:
                    alpha[j] = H
                elif alpha[j] < L:
                    alpha[j] = L

                if abs(alpha[j] - alpha_j_old) < tol:
                    continue

                # 更新 alpha[i]
                alpha[i] = alpha[i] + y[i]*y[j]*(alpha_j_old - alpha[j])

                # 更新 b
                b1 = b - E_i - y[i]*(alpha[i]-alpha_i_old)*K[i, i] - y[j]*(alpha[j]-alpha_j_old)*K[i, j]
                b2 = b - E_j - y[i]*(alpha[i]-alpha_i_old)*K[i, j] - y[j]*(alpha[j]-alpha_j_old)*K[j, j]

                if 0 < alpha[i] < C:
                    b = b1
                elif 0 < alpha[j] < C:
                    b = b2
                else:
                    b = (b1 + b2) / 2

                num_changed_alphas += 1

        # 在每個 epoch 結束後，利用目前模型預測訓練資料，計算 training accuracy
        y_pred_train = svm_predict(X, y, alpha, b, X, kernel_func)
        train_accuracy = np.mean(y_pred_train == np.where(y == -1, 0, 1))
        print(f"Epoch {epoch}: 改變的 alpha 數量 = {num_changed_alphas}, 當前 b = {b:.4f}, Training Accuracy = {train_accuracy:.4f}")
        
        if num_changed_alphas == 0:
            passes += 1
        else:
            passes = 0

    return alpha, b



###############################
# 預測函數：利用支持向量預測新資料
###############################
def svm_predict(X_train, y_train, alpha, b, X_new, kernel_func):
    sv_indices = np.where(alpha > 1e-5)[0]
    sv_alpha = alpha[sv_indices]
    sv_y = y_train[sv_indices]
    sv_X = X_train[sv_indices]
    
    predictions = []
    for i in range(X_new.shape[0]):
        s = 0
        for a, y_sv, x_sv in zip(sv_alpha, sv_y, sv_X):
            s += a * y_sv * kernel_func(x_sv, X_new[i])
        pred = s + b
        predictions.append(1 if pred >= 0 else 0)
    return np.array(predictions)

###############################
# 主程式
###############################
def main():
    # 讀取資料
    train_df = pd.read_csv("data/train.csv")
    test_df = pd.read_csv("data/test.csv")
    eval_df = pd.read_csv("data/eval.anon.csv")
    eval_ids = pd.read_csv("data/eval.id", header=None, names=["id"])

   # 假設所有以 "x" 開頭的欄位為特徵，標籤欄位為 "label"
    feature_cols = [col for col in train_df.columns if col.startswith("x")]

    def prepare_data(df):
        X = df[feature_cols].values.astype(float)
        y = df["label"].values
        # 將 0 轉換為 -1 (SVM 訓練時使用 -1 與 1)
        y = np.where(y == 0, -1, 1)
        return X, y
    X_train, y_train = prepare_data(train_df)
    X_test, y_test = prepare_data(test_df)
    X_eval, y_eval = prepare_data(eval_df)

    # 資料標準化 (SVM 對特徵尺度敏感)
    X_train, mean_train, std_train = standardize(X_train)
    X_test, _, _ = standardize(X_test, mean_train, std_train)
    X_eval, _, _ = standardize(X_eval, mean_train, std_train)

    #######################################
    # 特徵工程：利用 PCA 進行降維
    #######################################
    # 設定主成分數量，可根據資料特性調整
    n_components = min(20, X_train.shape[1])
    X_train, W, mean_pca = pca_transform(X_train, n_components)
    X_test, _, _ = pca_transform(X_test, n_components, W, mean_pca)
    X_eval, _, _ = pca_transform(X_eval, n_components, W, mean_pca)

    kernels = {
        "linear": {},
        "poly": {"gamma": 1.0, "r": 1.0, "degree": 4},
        "rbf": {"gamma": 0.05},
        "sigmoid": {"gamma": 0.01, "r": 0.0}
    }

    C = 1.0
    tol = 1e-4
    max_passes = 5

    # 建立 SVM 輸出資料夾 (如果不存在的話)
    output_folder = "SVM"
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    for kernel_type, params in kernels.items():
        print("========================================")
        print(f"使用 {kernel_type} kernel 訓練 SVM")
        kernel_func = get_kernel_function(kernel_type, params)

        alpha, b = smo_train(X_train, y_train, C=C, tol=tol, max_passes=max_passes, kernel_func=kernel_func)
        print(f"訓練完成, 支持向量數量: {np.sum(alpha > 1e-5)}")

        y_pred_test = svm_predict(X_train, y_train, alpha, b, X_test, kernel_func)
        test_accuracy = np.mean(y_pred_test == np.where(y_test == -1, 0, 1))
        print(f"Test Accuracy ({kernel_type}): {test_accuracy:.4f}")

        y_pred_eval = svm_predict(X_train, y_train, alpha, b, X_eval, kernel_func)
        eval_results = pd.DataFrame({
            "example_id": eval_ids["id"],
            "label": y_pred_eval
        })
        output_filename = os.path.join(output_folder, f"svm_eval_predictions_{kernel_type}.csv")
        eval_results.to_csv(output_filename, index=False)
        print(f"Evaluation 結果已存檔至 {output_filename}\n")

if __name__ == "__main__":
    main()
