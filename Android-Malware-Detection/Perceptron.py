import numpy as np
import pandas as pd
import argparse

def compute_accuracy(y_true, y_pred):
    return np.mean(y_true == y_pred)

# ---------------------------
# 1. Standard Perceptron
# ---------------------------
import numpy as np

class WeightedStandardPerceptron:
    def __init__(self, n_features, learning_rate=1.0, n_iter=1000, class_weights=None):
        # 初始化權重與偏置為 -0.01 到 0.01 之間的隨機數
        self.weights = np.random.uniform(-0.01, 0.01, size=n_features)
        self.bias = np.random.uniform(-0.01, 0.01)
        self.learning_rate = learning_rate
        self.n_iter = n_iter
        # class_weights 為字典，例如 {0: 1.0, 1: 1.5}，若不指定則視為所有樣本權重均為 1
        self.class_weights = class_weights

    def fit(self, X, y):
        # 若提供 class_weights，則建立每個樣本的權重陣列
        if self.class_weights is not None:
            sample_weights = np.array([self.class_weights[label] for label in y])
        else:
            sample_weights = np.ones(len(y), dtype=float)

        # 如果標籤為 {0, 1}，則轉換為 {-1, 1}（用於更新，但 sample_weights 仍依據原始標籤）
        unique_labels = np.unique(y)
        if set(unique_labels) == {0, 1}:
            y_conv = np.where(y == 0, -1, 1)
        else:
            y_conv = y

        for _ in range(self.n_iter):
            errors = 0
            for i, (xi, target) in enumerate(zip(X, y_conv)):
                # 如果預測錯誤，更新時乘上對應的 sample weight
                if target * (np.dot(xi, self.weights) + self.bias) <= 0:
                    update = self.learning_rate * sample_weights[i] * target
                    self.weights += update * xi
                    self.bias += update
                    errors += 1
            if errors == 0:
                break

    def predict(self, X):
        net = np.dot(X, self.weights) + self.bias
        preds = np.where(net >= 0, 1, -1)
        # 將 -1 轉換回 0
        return np.where(preds == -1, 0, preds)


# ---------------------------
# 2. Averaged Perceptron
# ---------------------------
class AveragedPerceptron:
    def __init__(self, n_features, learning_rate=1.0, n_iter=1000, class_weights=None):
        self.n_features = n_features
        self.learning_rate = learning_rate
        self.n_iter = n_iter
        self.class_weights = class_weights
        # 使用 -0.01 到 0.01 之間的隨機數初始化權重與偏置
        self.weights = np.random.uniform(-0.01, 0.01, size=n_features)
        self.bias = np.random.uniform(-0.01, 0.01)
        # 用於累加權重與偏置
        self.w_sum = np.zeros(n_features)
        self.b_sum = 0.0
        self.counter = 0  # 記錄累加次數

    def fit(self, X, y):
        # 若提供 class_weights，則根據原始標籤建立每個樣本的權重陣列；否則均為 1
        if self.class_weights is not None:
            sample_weights = np.array([self.class_weights[label] for label in y])
        else:
            sample_weights = np.ones(len(y), dtype=float)
        
        # 如果標籤為 {0, 1} 則轉換為 {-1, 1} 用於更新，但 sample_weights 保持根據原始 y
        unique_labels = np.unique(y)
        if set(unique_labels) == {0, 1}:
            y_conv = np.where(y == 0, -1, 1)
        else:
            y_conv = y
        
        # 初始化局部參數
        w = self.weights.copy()
        b = self.bias
        
        # 迭代訓練
        for epoch in range(self.n_iter):
            for i, (xi, target) in enumerate(zip(X, y_conv)):
                # 如果預測錯誤，則更新參數
                if target * (np.dot(xi, w) + b) <= 0:
                    update = self.learning_rate * sample_weights[i] * target
                    w += update * xi
                    b += update
                # 累加當前的 w 和 b
                self.w_sum += w
                self.b_sum += b
                self.counter += 1
        # 計算平均權重和偏置
        self.weights = self.w_sum / self.counter
        self.bias = self.b_sum / self.counter

    def predict(self, X):
        net = np.dot(X, self.weights) + self.bias
        preds = np.where(net >= 0, 1, -1)
        # 將 -1 轉換回 0
        return np.where(preds == -1, 0, preds)

# ---------------------------
# 3. Voted Perceptron
# ---------------------------
class VotedPerceptron:
    def __init__(self, n_features, learning_rate=1.0, n_iter=1000):
        self.n_features = n_features
        self.learning_rate = learning_rate
        self.n_iter = n_iter
        self.weights = []   # 存放各權重向量
        self.biases = []    # 存放各偏置
        self.counts = []    # 存放各向量出現次數

    def fit(self, X, y):
        unique_labels = np.unique(y)
        y_conv = np.where(y==0, -1, 1) if set(unique_labels)=={0,1} else y

        w = np.random.uniform(-0.01, 0.01, size=self.n_features)
        b = np.random.uniform(-0.01, 0.01)
        c = 1

        self.weights = []
        self.biases = []
        self.counts = []

        for epoch in range(self.n_iter):
            for xi, target in zip(X, y_conv):
                if target * (np.dot(xi, w) + b) <= 0:
                    self.weights.append(w.copy())
                    self.biases.append(b)
                    self.counts.append(c)
                    w += self.learning_rate * target * xi
                    b += self.learning_rate * target
                    c = 1
                else:
                    c += 1
        self.weights.append(w.copy())
        self.biases.append(b)
        self.counts.append(c)

    def predict(self, X):
        total_votes = np.zeros(X.shape[0])
        for w, b, count in zip(self.weights, self.biases, self.counts):
            preds = np.where(np.dot(X, w) + b >= 0, 1, -1)
            total_votes += count * preds
        final_preds = np.where(total_votes >= 0, 1, -1)
        return np.where(final_preds == -1, 0, final_preds)

# ---------------------------
# 4. Margin Perceptron
# ---------------------------
class MarginPerceptron:
    def __init__(self, n_features, learning_rate=1.0, n_iter=1000, mu=1.0, class_weights=None):
        self.n_features = n_features
        self.learning_rate = learning_rate
        self.n_iter = n_iter
        self.mu = mu
        self.class_weights = class_weights
        # 隨機初始化權重與偏置，範圍為 -0.01 ~ 0.01
        self.weights = np.random.uniform(-0.01, 0.01, size=n_features)
        self.bias = np.random.uniform(-0.01, 0.01)

    def fit(self, X, y):
        # 如果提供了 class_weights，根據原始標籤建立每個樣本的權重；否則默認為 1
        if self.class_weights is not None:
            sample_weights = np.array([self.class_weights[label] for label in y])
        else:
            sample_weights = np.ones(len(y), dtype=float)
            
        # 若標籤為 {0, 1} 則轉換為 {-1, 1}，用於更新；但 sample_weights 根據原始 y
        unique_labels = np.unique(y)
        if set(unique_labels) == {0, 1}:
            y_conv = np.where(y == 0, -1, 1)
        else:
            y_conv = y

        update_count = 0
        for epoch in range(self.n_iter):
            errors = 0
            for i, (xi, target) in enumerate(zip(X, y_conv)):
                # 若 margin 條件不滿足，即 target*(w^T x + b) < mu，則更新
                if target * (np.dot(xi, self.weights) + self.bias) < self.mu:
                    # 使用衰減學習率策略（可以根據更新次數調整）
                    current_lr = self.learning_rate / (1 + update_count)
                    update = current_lr * sample_weights[i] * target
                    self.weights += update * xi
                    self.bias += update
                    update_count += 1
                    errors += 1
            if errors == 0:
                break

    def predict(self, X):
        net = np.dot(X, self.weights) + self.bias
        preds = np.where(net >= 0, 1, -1)
        # 將 -1 轉換回 0
        return np.where(preds == -1, 0, preds)

# ---------------------------
# 5. Aggressive Perceptron with Margin (Grid search version)
# ---------------------------
class AggressiveMarginPerceptron:
    def __init__(self, n_features, n_iter=1000, mu=1.0, class_weights=None):
        self.n_features = n_features
        self.n_iter = n_iter
        self.mu = mu
        self.class_weights = class_weights
        # 使用 -0.01 ~ 0.01 的隨機數初始化權重與偏置
        self.weights = np.random.uniform(-0.01, 0.01, size=n_features)
        self.bias = np.random.uniform(-0.01, 0.01)

    def fit(self, X, y):
        # 如果提供 class_weights，根據原始標籤建立 sample_weights 陣列
        if self.class_weights is not None:
            sample_weights = np.array([self.class_weights[label] for label in y])
        else:
            sample_weights = np.ones(len(y), dtype=float)

        # 如果標籤是 {0, 1}，轉換成 {-1, 1} 用於更新，但 sample_weights 依據原始 y
        unique_labels = np.unique(y)
        if set(unique_labels) == {0, 1}:
            y_conv = np.where(y == 0, -1, 1)
        else:
            y_conv = y

        for epoch in range(self.n_iter):
            errors = 0
            for i, (xi, target) in enumerate(zip(X, y_conv)):
                net_val = np.dot(xi, self.weights) + self.bias
                margin = target * net_val
                if margin <= self.mu:
                    # 攻擊性更新率 eta
                    eta = (self.mu - margin) / (np.dot(xi, xi) + 1)
                    # 更新時乘上 sample_weights[i]
                    self.weights += eta * sample_weights[i] * target * xi
                    self.bias += eta * sample_weights[i] * target
                    errors += 1
            if errors == 0:
                break

    def predict(self, X):
        net = np.dot(X, self.weights) + self.bias
        preds = np.where(net >= 0, 1, -1)
        # 將 -1 轉換為 0
        return np.where(preds == -1, 0, preds)

# ---------------------------
# 6. Decaying Learning Rate Perceptron
# ---------------------------
class DecayingLearningRatePerceptron:
    def __init__(self, n_features, learning_rate=0.1, n_iter=3000, class_weights=None):
        self.n_features = n_features
        self.initial_lr = learning_rate    # 初始學習率 η0
        self.n_iter = n_iter
        self.class_weights = class_weights  # 字典，例如 {0: weight0, 1: weight1}
        # 隨機初始化權重與偏置在 -0.01 到 0.01 之間
        self.weights = np.random.uniform(-0.01, 0.01, size=n_features)
        self.bias = np.random.uniform(-0.01, 0.01)
        self.t = 0  # 全局時間步，跨 epoch 持續累加

    def fit(self, X, y):
        # 若提供 class_weights，根據原始標籤建立每個樣本的權重陣列；否則默認為 1
        if self.class_weights is not None:
            sample_weights = np.array([self.class_weights[label] for label in y])
        else:
            sample_weights = np.ones(len(y), dtype=float)
        
        # 如果標籤為 {0, 1}，則將其轉換為 {-1, 1} 用於更新，但 sample_weights 依然根據原始 y
        unique_labels = np.unique(y)
        y_conv = np.where(y == 0, -1, 1) if set(unique_labels) == {0, 1} else y

        for epoch in range(self.n_iter):
            errors = 0
            current_lr = self.initial_lr / (1 + self.t)
            for xi, target, s_weight in zip(X, y_conv, sample_weights):
                if target * (np.dot(xi, self.weights) + self.bias) <= 0:
                    # 更新量同時乘上該樣本的權重
                    self.weights += current_lr * s_weight * target * xi
                    self.bias += current_lr * s_weight * target
                    errors += 1
            self.t += 0.001  # 每個 epoch 後增加全局時間步 t
            if errors == 0:
                break

    def predict(self, X):
        net = np.dot(X, self.weights) + self.bias
        preds = np.where(net >= 0, 1, -1)
        return np.where(preds == -1, 0, preds)

# ---------------------------
# 主程式：讀取資料、模型選擇、以及 Grid Search 測試超參數
# ---------------------------
def main():
    parser = argparse.ArgumentParser(
        description="選擇 Perceptron 模型、初始學習率、迭代次數及 margin 參數，並執行訓練、評估與生成 eval 預測結果。"
    )
    parser.add_argument('--model', type=str,
                        choices=['standard', 'averaged', 'voted', 'margin', 'aggressive', 'decaying'],
                        default='standard',
                        help="模型類型 (預設 standard)")
    parser.add_argument('--lr', type=float, default=1.0,
                        help="初始學習率 (預設 1.0)。對 aggressive 模型不適用。")
    parser.add_argument('--epoch', type=int, default=1000,
                        help="迭代次數 (預設 1000)")
    parser.add_argument('--mu', type=float, default=1.0,
                        help="margin 參數 μ (預設 1.0)，適用於 margin 及 aggressive 模型")
    parser.add_argument('--grid', action='store_true',
                        help="若指定此參數，則執行 grid search 測試不同超參數組合")
    args = parser.parse_args()

    # 讀取訓練資料：假設特徵以 "x" 開頭，標籤為 "label"
    train_df = pd.read_csv("data/train.csv")
    feature_columns = [col for col in train_df.columns if col.startswith("x")]
    X_train = train_df[feature_columns].values
    y_train = train_df["label"].values

    # 計算 class_weights：每個類別的權重 = total_samples / (n_classes * count)
    unique, counts = np.unique(y_train, return_counts=True)
    total_samples = len(y_train)
    n_classes = len(unique)
    class_weights = {label: total_samples / (n_classes * count) for label, count in zip(unique, counts)}
    print("Computed class weights:", class_weights)

    # 讀取 test 資料（若有標籤則計算準確率）
    test_df = pd.read_csv("data/test.csv")
    if "label" in test_df.columns:
        X_test = test_df[feature_columns].values
        y_test = test_df["label"].values
    else:
        X_test = test_df[feature_columns].values
        y_test = None

    n_features = X_train.shape[1]

    # 如果指定 --grid 則執行 grid search 測試超參數
    if args.grid:
        # 預設超參數列表（可根據需要調整）
        lr_list = [0.001 , 0.005, 0.01, 0.05 , 0.1 , 1]
        epoch_list = [500, 1000 , 5000 , 10000 , 15000 , 16000 , 17000 , 18000 , 19000 , 20000]
        # 只有 margin 與 aggressive 模型才使用 mu 參數
        if args.model in ['margin', 'aggressive']:
            lr_list = [0]
            mu_list = [0.01 , 0.05 , 0.1, 0.5, 1.0, 5.0 , 10]
        else:
            mu_list = [args.mu]
            
        best_test_acc = -1.0
        best_config = None
        for lr in lr_list:
            for mu in mu_list:
                for epoch in epoch_list:
                    if args.model == "standard":
                        #n_features = X_train.shape[1]
                        class_weights = {0: 1 , 1: 1.5}
                        model = WeightedStandardPerceptron(n_features=n_features, learning_rate=0.01, n_iter=epoch, class_weights=class_weights)
                    elif args.model == "averaged":
                        #n_features = X_train.shape[1]
                        class_weights = {0: 1 , 1: 1.5}
                        model = AveragedPerceptron(n_features=n_features, learning_rate=lr, n_iter=epoch , class_weights=class_weights)
                    elif args.model == "voted":
                        model = VotedPerceptron(n_features=n_features, learning_rate=lr, n_iter=epoch)
                    elif args.model == "margin":
                        n_features = X_train.shape[1]
                        #class_weights = {0: 1 , 1: 1.5}
                        model = MarginPerceptron(n_features=n_features, learning_rate=lr, n_iter=epoch, mu=mu , class_weights=class_weights)
                    elif args.model == "aggressive":
                        #n_features = X_train.shape[1]
                        class_weights = {0: 1 , 1: 1.5}
                        model = AggressiveMarginPerceptron(n_features=n_features, n_iter=epoch, mu=mu , class_weights=class_weights)
                    elif args.model == "decaying":
                        n_features = X_train.shape[1]
                        class_weights = {0: 1 , 1: 1.5}
                        model = DecayingLearningRatePerceptron(n_features=n_features, learning_rate=lr, n_iter=epoch , class_weights=class_weights)
                    else:
                        raise ValueError("不支援的模型類型！")
                    
                    model.fit(X_train, y_train)
                    if y_test is not None:
                        test_preds = model.predict(X_test)
                        test_acc = compute_accuracy(y_test, test_preds)
                        print("Model: {}, lr: {}, mu: {}, epoch: {}, test_acc: {:.2f}%".format(
                            args.model, lr, mu, epoch, test_acc*100))
                        if test_acc > best_test_acc:
                            best_test_acc = test_acc
                            best_config = (lr, mu, epoch)
        print("最佳組合 (model: {}): lr: {}, mu: {}, epoch: {}，test_acc: {:.2f}%".format(
            args.model, best_config[0], best_config[1], best_config[2], best_test_acc*100))
        # 使用最佳組合重新訓練模型
        chosen_lr, chosen_mu, chosen_epoch = best_config
        if args.model == "standard":
            #n_features = X_train.shape[1]
            class_weights = {0: 1, 1: 1.5}
            model = WeightedStandardPerceptron(n_features=n_features, learning_rate=0.01, n_iter=chosen_epoch , class_weights=class_weights)
        elif args.model == "averaged":
            #n_features = X_train.shape[1]
            class_weights = {0: 1, 1: 1.5}
            model = AveragedPerceptron(n_features=n_features, learning_rate=chosen_lr, n_iter=chosen_epoch , class_weights=class_weights)
        elif args.model == "voted":
            model = VotedPerceptron(n_features=n_features, learning_rate=chosen_lr, n_iter=chosen_epoch)
        elif args.model == "margin":
            n_features = X_train.shape[1]
            #class_weights = {0: 1, 1: 1.5}
            model = MarginPerceptron(n_features=n_features, learning_rate=chosen_lr, n_iter=chosen_epoch, mu=chosen_mu , class_weights=class_weights)
        elif args.model == "aggressive":
            #n_features = X_train.shape[1]
            class_weights = {0: 1 , 1: 1.5}
            model = AggressiveMarginPerceptron(n_features=n_features, n_iter=chosen_epoch, mu=chosen_mu , class_weights=class_weights)
        elif args.model == "decaying":
            #n_features = X_train.shape[1]
            class_weights = {0: 1 , 1: 1.5}
            model = DecayingLearningRatePerceptron(n_features=n_features, learning_rate=chosen_lr, n_iter=chosen_epoch , class_weights=class_weights)
        else:
            raise ValueError("不支援的模型類型！")
        print("使用最佳參數重新訓練模型...")
        model.fit(X_train, y_train)
    else:
        # 不使用 grid search，直接用命令列參數建立模型
        if args.model == "standard":
            #n_features = X_train.shape[1]
            class_weights = {0: 1, 1: 1.5}
            model = WeightedStandardPerceptron(n_features=n_features, learning_rate=0.01, n_iter=args.epoch, class_weights=class_weights)
        elif args.model == "averaged":
            #n_features = X_train.shape[1]
            class_weights = {0: 1, 1: 1.5}
            model = AveragedPerceptron(n_features=n_features, learning_rate=args.lr, n_iter=args.epoch , class_weights=class_weights)
        elif args.model == "voted":
            model = VotedPerceptron(n_features=n_features, learning_rate=args.lr, n_iter=args.epoch)
        elif args.model == "margin":
            n_features = X_train.shape[1]
            #class_weights = {0: 1, 1: 1.5}
            model = MarginPerceptron(n_features=n_features, learning_rate=args.lr, n_iter=args.epoch, mu=args.mu , class_weights=class_weights)
        elif args.model == "aggressive":
            #n_features = X_train.shape[1]
            class_weights = {0: 1 , 1: 1.5}
            model = AggressiveMarginPerceptron(n_features=n_features, n_iter=args.epoch, mu=args.mu , class_weights=class_weights)
        elif args.model == "decaying":
            n_features = X_train.shape[1]
            #class_weights = {0: 1 , 1: 1.5}
            model = DecayingLearningRatePerceptron(n_features=n_features, learning_rate=args.lr, n_iter=args.epoch , class_weights=class_weights)
        else:
            raise ValueError("不支援的模型類型！")
        model.fit(X_train, y_train)

    print("使用 {} 模型訓練完成。".format(args.model))
    train_preds = model.predict(X_train)
    train_acc = compute_accuracy(y_train, train_preds)
    print("Training Accuracy: {:.2f}%".format(train_acc * 100))
    if y_test is not None:
        test_preds = model.predict(X_test)
        test_acc = compute_accuracy(y_test, test_preds)
        print("Test Accuracy: {:.2f}%".format(test_acc * 100))
    else:
        print("Test data 沒有標籤，無法計算 test accuracy.")

    # --- 对 eval.anon 数据进行预测 ---
    eval_data = pd.read_csv("./data/eval.anon.csv")
    X_eval = eval_data[feature_columns].values
    eval_preds = model.predict(X_eval)

    # 读取 eval 的 id 文件，并将 id 与预测结果结合
    eval_ids = pd.read_csv("./data/eval.id", header=None, names=["id"])
    eval_output = pd.DataFrame({"example_id": eval_ids["id"], "label": eval_preds})
    if args.model == "standard":
        eval_output.to_csv("./Perception/Weightedstd.csv", index=False)
    if args.model == "voted":
        eval_output.to_csv("./Perception/WeightedVoted.csv", index=False)
    if args.model == "margin":
        eval_output.to_csv("./Perception/WeightedMargin.csv", index=False)
    if args.model == "aggressive":
        eval_output.to_csv("./Perception/WeightedAgg.csv", index=False)
    if args.model == "decaying":
        eval_output.to_csv("./Perception/WeightedDecay.csv", index=False)
    if args.model == "averaged":
        eval_output.to_csv("./Perception/WeightedAve.csv", index=False)
    
    print("预测完成，并已生成 eval_predictions.csv 文件。")

if __name__ == "__main__":
    main()
