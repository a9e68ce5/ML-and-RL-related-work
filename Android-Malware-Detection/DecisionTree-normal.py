import numpy as np
import pandas as pd
from collections import Counter
from math import log2

class OptimizedDecisionTree:
    def __init__(self, max_depth=5, num_thresholds=10):
        self.max_depth = max_depth
        self.num_thresholds = num_thresholds
        self.tree = None

    def _collision_entropy(self, labels):
        total = len(labels)
        counts = Counter(labels)
        return -log2(sum((count / total) ** 2 for count in counts.values()))

    def _information_gain(self, y, left_y, right_y):
        parent_entropy = self._collision_entropy(y)
        left_entropy = self._collision_entropy(left_y)
        right_entropy = self._collision_entropy(right_y)
        
        left_weight = len(left_y) / len(y)
        right_weight = len(right_y) / len(y)
        
        return parent_entropy - (left_weight * left_entropy + right_weight * right_entropy)

    def best_split(self, X, y):
        best_feature, best_threshold, best_gain = None, None, -float('inf')

        for feature in range(X.shape[1]):
            thresholds = np.linspace(np.min(X[:, feature]), np.max(X[:, feature]), self.num_thresholds)
            for threshold in thresholds:
                left_mask = X[:, feature] <= threshold
                right_mask = ~left_mask

                if np.sum(left_mask) == 0 or np.sum(right_mask) == 0:
                    continue

                gain = self._information_gain(y, y[left_mask], y[right_mask])
                
                if gain > best_gain:
                    best_feature, best_threshold, best_gain = feature, threshold, gain

        return best_feature, best_threshold

    def build_tree(self, X, y, depth=0):
        if depth >= self.max_depth or len(np.unique(y)) == 1:
            return np.argmax(np.bincount(y))

        feature, threshold = self.best_split(X, y)
        if feature is None:
            return np.argmax(np.bincount(y))

        left_mask = X[:, feature] <= threshold
        right_mask = ~left_mask

        return {
            'feature': feature,
            'threshold': threshold,
            'left': self.build_tree(X[left_mask], y[left_mask], depth + 1),
            'right': self.build_tree(X[right_mask], y[right_mask], depth + 1)
        }

    def fit(self, X, y):
        self.tree = self.build_tree(X, y)

    def predict_one(self, x, node):
        if isinstance(node, dict):
            if x[node['feature']] <= node['threshold']:
                return self.predict_one(x, node['left'])
            else:
                return self.predict_one(x, node['right'])
        return node

    def predict(self, X):
        return np.array([self.predict_one(x, self.tree) for x in X])

# Load datasets
train_df = pd.read_csv("./data/train.csv")
test_df = pd.read_csv("./data/test.csv")
eval_anon_df = pd.read_csv("./data/eval.anon.csv", header=None)
eval_id_df = pd.read_csv("./data/eval.id", header=None)

# Prepare training data
X_train = train_df.drop(columns=["label"]).values
y_train = train_df["label"].values

# Train the decision tree
optimized_tree = OptimizedDecisionTree(max_depth=5, num_thresholds=10)
optimized_tree.fit(X_train, y_train)

# Evaluate on test set
X_test = test_df.drop(columns=["label"]).values
y_test = test_df["label"].values
predictions_test = optimized_tree.predict(X_test)

# Function to calculate accuracy
def accuracy(y_true, y_pred):
    return np.sum(y_true == y_pred) / len(y_true)

# Function to calculate precision, recall, and F1 score
def precision_recall_f1(y_true, y_pred):
    tp = np.sum((y_true == 1) & (y_pred == 1))
    fp = np.sum((y_true == 0) & (y_pred == 1))
    fn = np.sum((y_true == 1) & (y_pred == 0))
    
    precision = tp / (tp + fp) if (tp + fp) > 0 else 0
    recall = tp / (tp + fn) if (tp + fn) > 0 else 0
    f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
    
    return precision, recall, f1

# Calculate and print training and testing accuracy
train_predictions = optimized_tree.predict(X_train)
test_accuracy = accuracy(y_test, predictions_test)
train_accuracy = accuracy(y_train, train_predictions)

# Calculate precision, recall, and F1 score
precision, recall, f1_score = precision_recall_f1(y_test, predictions_test)

print(f"Training Accuracy: {train_accuracy:.4f}")
print(f"Testing Accuracy: {test_accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1 Score: {f1_score:.4f}")

# Prepare evaluation data
X_eval = eval_anon_df.iloc[1:].astype(float).values
eval_ids = eval_id_df[0].values

# Predict on evaluation data
predictions = optimized_tree.predict(X_eval)

# Create the submission file
submission_df = pd.DataFrame({"example_id": eval_ids, "label": predictions})
submission_path = "submission.csv"
submission_df.to_csv(submission_path, index=False)

# Display first few rows of the submission file
print(submission_df.head())
